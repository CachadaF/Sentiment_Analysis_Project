{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proyecto final - Sentiment Analysis - ML Lab ITBA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Objetivos:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Lograr una aplicación que pueda \"predecir\" los sentimientos en un comentario o review en Amazon de forma binaria:\n",
    "    - 1 : Positivo.\n",
    "\t- 0 : Negativo.\n",
    "- Hacer uso de los distintos modelos y las distintas técnicas aprendidas durante el Laboratorio de Machine Learning.\n",
    "- Lograr, a futuro, disponibilizar mediante una aplicación web el mejor modelo para poder hacer predicciones de distintos reviews/comentarios en páginas en ingles (Esto no se si podría hacerse)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset: Amazon Reviews for Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Como su nombre lo indica, el Dataset está compuesto de reviews de Amazon.\n",
    "- Consiste en alrededor de 4.000.000 de Reviews con sus respectivos labels:\n",
    "    - label1 -> Negative\n",
    "        - Corresponde a las reviews de 1 y 2 estrellas.\n",
    "    - label2 -> Positive\n",
    "        - Corresponde a las reviews de 4 y 5 estrellas.\n",
    "- Nota: Las reviews de 3 estrellas no se incluyen debido a que se considera un sentimiento neutral\n",
    "- División del Dataset:\n",
    "    - Cantidad de elementos del Training Set: 3.600.000\n",
    "    - Cantidad de elementos del Testing Set: 400.000\n",
    "- Link al dataset: https://www.kaggle.com/bittlingmayer/amazonreviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejemplo de Review:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'__label__2 Good shape but a a little worn: My book was in good shape but a little worn. Not quite the \"like new\" I expected but still worth the price.\\n'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocesamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se trató de normalizar las reviews mediante el uso de distintas funciones:\n",
    "\n",
    "1- Se realizó la siguiente transformación de las labels:\n",
    "    \n",
    "    '__label__1' -> 0 (Negative)\n",
    "    '__label__2' -> 1 (Positive)\n",
    "\n",
    "2- Se le aplico una limpieza a las distintas palabras que componian la review (Por ejemplo, un \"lower()\").\n",
    "\n",
    "3- Se eliminaron las urls ( Con \"www.\", \"http:\", \"https:\", etc) ya que aparecerian repetidas en varios textos.\n",
    "\n",
    "Nota: Podría mejorarse la limpieza que se hace a los datos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ejemplo - Data before cleaning:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'__label__2 Good shape but a a little worn: My book was in good shape but a little worn. Not quite the \"like new\" I expected but still worth the price.\\n'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ejemplo - Data after cleaning:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'good shape but a a little worn: my book was in good shape but a little worn. not quite the \"like new\" i expected but still worth the price.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El preprocesado se hizo mediante CountVectorizer de Sklearn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El preprocesado se hizo mediante el Word Tokenizer de Keras.\n",
    "\n",
    "Link : https://keras.io/preprocessing/text/\n",
    "\n",
    "Con esta clave se arma un vector a partir de un \"text corpus\", transformando cada texto en una secuencia de \"integers\".\n",
    "\n",
    "Ademas, se le aplicaron distintos filtros para eliminar caracteres especiales como las comillas, parentesis, corchetes, etcetera.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analizando los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](Others/Count.png\"Title\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "![alt text](Others/Count.png\"Title\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelos clásicos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelos mixtos (MLP,CNN,RNN,etcetera)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FastText supervised learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusiones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- En este caso, tanto un MLP como un modelo mas complejo obtienen muy buenos resultados al clasificar los sentimientos (Arriba de 0,9 de Accuracy).\n",
    "- De los modelos construidos, el de 2 Layers CNN + LSTM es el que obtuvo el Accuracy más alto (0,942...), pero es el más tiempo demoró en entrenar (Cerca de 30 minutos por Epochs haciendo uso de una GPU - Nvidia K80).\n",
    "- Respecto al punto anterior, se pudieron correr todos los modelos en Kaggle logrando una gran disminución en el tiempo de Procesamiento.\n",
    "- Fue una buena práctica para obtener conocimientos acerca de las distintas libraries que nos provee Python (Keras, Numpy,etc.), así como para fijar conocimientos teóricos.\n",
    "- Se podría probar a futuro otras variantes de modelos, así como variar los hiperparámetros."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
