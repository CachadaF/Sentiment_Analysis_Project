{
  "cells": [
    {
      "metadata": {
        "trusted": true,
        "_uuid": "433d791fa63fed8ca6c2e72ef3f706bd36f69e8f",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "%load_ext autoreload\n%autoreload 2",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "4dd662d39b7605517f4e8d44f1925e4b7559f61e"
      },
      "cell_type": "code",
      "source": "import numpy as np \nimport pandas as pd \nimport bz2\nimport gc\nimport chardet\nimport re\nimport os\nimport random",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "7b404ad0dcc33a9f313cf452b0bea553a1bb82f6"
      },
      "cell_type": "markdown",
      "source": "# Pre-processing"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "ac33294d1ecf3b86e0db762f246acb73c0440f4f",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "#Checking files in Kaggle\n# List data files that are connected to the kernel\nos.listdir('../input')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "8baaebd44216dfdf4ff111acce0690760de706c0",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "# Read Train & Test Files\n\n#Kaggle\ntrain_file = bz2.BZ2File('../input/train.ft.txt.bz2')\ntest_file = bz2.BZ2File('../input/test.ft.txt.bz2')\n\n#Localhost\n#train_file = bz2.BZ2File('C:/Users/Lenovo/Documents/GitHub/Datasets/amazonreviews/train.ft.txt.bz2')\n#test_file = bz2.BZ2File('C:/Users/Lenovo/Documents/GitHub/Datasets/amazonreviews/test.ft.txt.bz2')\n\n#Localhost - Versión recortada del archivo\n#train_file = bz2.BZ2File('C:/Users/Lenovo/Documents/GitHub/Datasets/amazonreviews/Version_Recortada/r_train.ft.txt.bz2')\n#test_file = bz2.BZ2File('C:/Users/Lenovo/Documents/GitHub/Datasets/amazonreviews/Version_Recortada/r_test.ft.txt.bz2')\n\n#Create Lists containing Train & Test sentences\ntrain_file_lines = train_file.readlines()\ntest_file_lines = test_file.readlines()\n\n#Convert from raw binary strings to strings that can be parsed\ntrain_file_lines = [x.decode('utf-8') for x in train_file_lines]\ntest_file_lines = [x.decode('utf-8') for x in test_file_lines]",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "22e5858babb6998f63d1f743bcff69559beea13e",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "#Delete memory reference (?)\ndel train_file, test_file\n#Garbage collector\ngc.collect()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "db3f94ee387a44b0827df0ca90081e7960e581b2",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "print(\"Cantidad de elementos del Training Set: {}\".format(len(train_file_lines)))\nprint(\"Cantidad de elementos del Testing Set: {}\".format(len(test_file_lines)))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "e3d855e923c29dc8cfce89b35fd862a2b3aa5bba"
      },
      "cell_type": "markdown",
      "source": "## Clean data"
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "df31b59181d7e423fbb16d1405fed7ad62b1cbcd"
      },
      "cell_type": "code",
      "source": "# Change labels: __label__1 -> 0 (Negative) / __label__2 -> 1 (Positive)\ntrain_labels = [0 if x.split(' ')[0] == '__label__1' else 1 for x in train_file_lines]\ntest_labels = [0 if x.split(' ')[0] == '__label__1' else 1 for x in test_file_lines]\n\n# Make everything Lower Case\ntrain_sentences = [x.split(' ', 1)[1][:-1].lower() for x in train_file_lines]\n\nfor i in range(len(train_sentences)):\n    train_sentences[i] = re.sub('\\d','0',train_sentences[i])\n    \ntest_sentences = [x.split(' ', 1)[1][:-1].lower() for x in test_file_lines]\n\nfor i in range(len(test_sentences)):\n    test_sentences[i] = re.sub('\\d','0',test_sentences[i])\n\n# Modify URLs to <url>\nfor i in range(len(train_sentences)):\n    if 'www.' in train_sentences[i] or 'http:' in train_sentences[i] or 'https:' in train_sentences[i] or '.com' in train_sentences[i]:\n        train_sentences[i] = re.sub(r\"([^ ]+(?<=\\.[a-z]{3}))\", \"<url>\", train_sentences[i])\n        \nfor i in range(len(test_sentences)):\n    if 'www.' in test_sentences[i] or 'http:' in test_sentences[i] or 'https:' in test_sentences[i] or '.com' in test_sentences[i]:\n        test_sentences[i] = re.sub(r\"([^ ]+(?<=\\.[a-z]{3}))\", \"<url>\", test_sentences[i])",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "21719af8e34a93ecb7d9a97416f75b4a7e137a9a"
      },
      "cell_type": "markdown",
      "source": "## Checking data before and after cleaning"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "8c03fbfe4735456cf3c0298c4747feba3424146d",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "#Random\nr = random.randint(1,len(train_file_lines))\n\n#Before\nprint(\"Data before cleaning:\\n{}\".format(train_file_lines[r-1:r]))\n\n#After\nprint(\"\\nData after cleaning:\\n{}\".format((train_sentences[r-1:r])))\n\n#Labels\nprint(\"\\nLabel:{}\".format(train_labels[r-1:r]))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "c9a98cc678b3294d1ed9f86b36f3edc7e0cc690c"
      },
      "cell_type": "markdown",
      "source": "### Output\nFrom the above output it can be seen that each sentence begins with it's sentiment (label1 -> Negative, label2 -> Positive), which is then followed by the review and ends with a newline character \\n.\n\nSo, first I go convert all the labels to O(Negative) and 1(Positive) and store it in lists that only contain the label values. After this, I store the remainder of the sentence excluding the newline character in lowercase in lists. Also, convert all numbers to 0.\n"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "96d7d285b63ffa8ddf0a70e8df2f4d765b8073e5",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "#Delete memory reference (?)\ndel train_file_lines, test_file_lines\n#Garbage collector\ngc.collect()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "4bf6a4ae2b9cdb72178ccb1afb63795c88efb866"
      },
      "cell_type": "markdown",
      "source": "## Text Pre-processing"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "cac4d50ebe788b552a7c85fd21951f1cbe513533",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "from keras.preprocessing import text, sequence\n\n#Base definitions for text preprocessing\nmax_features = 20000\nmaxlen = 100",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "78fdef3b5107224fecba3cc4720eb693b2f048ff"
      },
      "cell_type": "code",
      "source": "#Tokenizer definition\n#Filtro caracteres especiales usando el Tokenizer de keras.\ntokenizer = text.Tokenizer(num_words=max_features, filters='!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~')\n\n#Fit on text -> Only the train dataset !!!\ntokenizer.fit_on_texts(train_sentences)\n\n#Training set\ntokenized_train = tokenizer.texts_to_sequences(train_sentences)\nX_train = sequence.pad_sequences(tokenized_train, maxlen=maxlen)\n\n#Test set\ntokenized_test = tokenizer.texts_to_sequences(test_sentences)\nX_test = sequence.pad_sequences(tokenized_test, maxlen=maxlen)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "becc7ba40bc713cec836c5ae061bc6553c4342dc",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "#Print a random matrix\nX_train[r]\n# summarize what was learned -> Si quiero ver el tokenizer que aprendio usando los 2 parametros (Max_features,max_length)\n#print(t.word_counts)\n#print(t.document_count)\n#print(t.word_index)\n#print(t.word_docs)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "5381cf4aa759c3cde8c1a3bc775c71eaa0debfae"
      },
      "cell_type": "markdown",
      "source": "### Validation dataset"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "034188709597cb9a4390840f8b4010b8e66a5b13",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "from sklearn.model_selection import train_test_split\n# Create a validation dataset\nvalidation_size = 0.2\nX_train, X_valid, train_labels, valid_labes = train_test_split(X_train, train_labels, test_size = validation_size)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "f9c36b66bfc3f7cfe53c50505956e443b643c319",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "#Delete memory reference (?)\ndel tokenized_test, tokenized_train, tokenizer, train_sentences, test_sentences\n#Garbage collector\ngc.collect()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "4442dfc514e5e9228aab0fec45e04d55a400b35d"
      },
      "cell_type": "markdown",
      "source": "## Model"
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "666878741c1705787c1e9f6d3cc882ee3000b6c5"
      },
      "cell_type": "code",
      "source": "from keras.utils import to_categorical\nfrom keras.callbacks import ModelCheckpoint \nfrom keras.layers.core import Dense, Dropout, Activation, Flatten\nfrom keras.layers.normalization import BatchNormalization\nfrom keras import optimizers\nfrom keras import initializers\nfrom keras.models import Model, Sequential\nfrom keras.layers import Convolution1D, MaxPooling1D, GlobalAveragePooling1D, BatchNormalization, LSTM, GRU\nfrom keras.layers.embeddings import Embedding",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "f352c6d9b432671718da6f2d64083796924ebb28"
      },
      "cell_type": "code",
      "source": "#Defino los parametros del modelo:\np = 0.10 #Dropout\nlr = 0.0001 #Learning Rate\nbatch_size = 2048\nepochs = 4 #Bajamos de 10 -> 4.\n\n#Embedding size -> Ver para que sirve, todavia falta entenderlo?\nembed_size = 128\n#CNN_Filters\nCNN_Filters = embed_size * 2\n#RNN\nRNN_Neurons = 128\ntime_steps = 0",
      "execution_count": 58,
      "outputs": []
    },
    {
      "metadata": {
        "scrolled": true,
        "trusted": true,
        "_uuid": "d3e60f578e04bea6df79525c9542e5dec03ac19d"
      },
      "cell_type": "code",
      "source": "# Creo el modelo\nmodel=Sequential()\n#Embedding\nmodel.add(Embedding(max_features, embed_size, input_length=maxlen))\nmodel.add(Dropout(p))\n#CNN\nmodel.add(Convolution1D(filters=CNN_Filters, kernel_size=3, padding=\"same\", name='Conv1'))\nmodel.add(Activation('relu'))\nmodel.add(Convolution1D(filters=CNN_Filters, kernel_size=3, padding=\"same\", name='Conv2'))\nmodel.add(Activation('relu'))\n#RNN\nmodel.add(GRU(RNN_Neurons, return_sequences=True))\nmodel.add(Dropout(p * 2))\nmodel.add(GRU(RNN_Neurons * 2, return_sequences=True))\nmodel.add(GRU(RNN_Neurons * 4))\n#Dense\nmodel.add(Dropout(p * 2))\nmodel.add(Dense(64))\nmodel.add(Activation('relu'))\n\nmodel.add(Dropout(p))\nmodel.add(Dense(1, activation='softmax'))\n\nmodel.summary()\n\n#Optimizers\nADAM = optimizers.Adam(lr=lr)\nmodel.compile(loss = 'binary_crossentropy', optimizer=ADAM, metrics=['binary_accuracy'])\n#Accuracy en metrics es más generico, y depende de la LOSS.\n#model.compile(loss = 'binary_crossentropy', optimizer=ADAM, metrics=['accuracy'])",
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": "_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nembedding_18 (Embedding)     (None, 100, 128)          2560000   \n_________________________________________________________________\ndropout_34 (Dropout)         (None, 100, 128)          0         \n_________________________________________________________________\nConv1 (Conv1D)               (None, 100, 256)          98560     \n_________________________________________________________________\nactivation_27 (Activation)   (None, 100, 256)          0         \n_________________________________________________________________\nConv2 (Conv1D)               (None, 100, 256)          196864    \n_________________________________________________________________\nactivation_28 (Activation)   (None, 100, 256)          0         \n_________________________________________________________________\ngru_4 (GRU)                  (None, 100, 128)          147840    \n_________________________________________________________________\ndropout_35 (Dropout)         (None, 100, 128)          0         \n_________________________________________________________________\ngru_5 (GRU)                  (None, 100, 256)          295680    \n_________________________________________________________________\ngru_6 (GRU)                  (None, 512)               1181184   \n_________________________________________________________________\ndropout_36 (Dropout)         (None, 512)               0         \n_________________________________________________________________\ndense_28 (Dense)             (None, 64)                32832     \n_________________________________________________________________\nactivation_29 (Activation)   (None, 64)                0         \n_________________________________________________________________\ndropout_37 (Dropout)         (None, 64)                0         \n_________________________________________________________________\ndense_29 (Dense)             (None, 1)                 65        \n=================================================================\nTotal params: 4,513,025\nTrainable params: 4,513,025\nNon-trainable params: 0\n_________________________________________________________________\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "a0611cfd88f87e629154694961c17ddf6e763002"
      },
      "cell_type": "code",
      "source": "# Callbacks\n\n## Callback para guardar pesos\ncheckpointer = ModelCheckpoint(filepath='Sentiment_Analysis_Amazon_Reviews.hdf5', monitor='val_loss'\n                                   ,verbose=1, save_best_only=True, mode='min')\ncallbacks = [checkpointer]",
      "execution_count": 61,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "360004b4d48a606985a235a8f263b5457ab75bef"
      },
      "cell_type": "code",
      "source": "# Fit del modelo\n\"\"\"\nmodel.fit(X_train,train_labels\n          ,epochs=epochs\n          ,batch_size = batch_size          \n          ,shuffle = True\n          ,validation_data = (X_valid,valid_labes)\n          ,callbacks=callbacks)\n\"\"\"\n\n# Fit del modelo -> Usando solo un fragmento del datasset\nmodel.fit(X_train[:100000], train_labels[:100000]\n          ,epochs=epochs\n          ,batch_size = batch_size          \n          ,shuffle = True\n          ,validation_split=0.20\n          ,callbacks=callbacks)\n",
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Train on 80000 samples, validate on 20000 samples\nEpoch 1/4\n80000/80000 [==============================] - 118s 1ms/step - loss: 7.9945 - binary_accuracy: 0.4985 - val_loss: 7.9696 - val_binary_accuracy: 0.5001\n\nEpoch 00001: val_loss improved from inf to 7.96960, saving model to Sentiment_Analysis_Amazon_Reviews.hdf5\nEpoch 2/4\n80000/80000 [==============================] - 117s 1ms/step - loss: 7.9945 - binary_accuracy: 0.4985 - val_loss: 7.9696 - val_binary_accuracy: 0.5001\n\nEpoch 00002: val_loss did not improve\nEpoch 3/4\n69632/80000 [=========================>....] - ETA: 14s - loss: 8.0037 - binary_accuracy: 0.4980",
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-63-346457324be7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m           \u001b[0;34m,\u001b[0m\u001b[0mshuffle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m           \u001b[0;34m,\u001b[0m\u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.20\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m           ,callbacks=callbacks)\n\u001b[0m",
            "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/Keras-2.1.5-py3.6.egg/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m    961\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    962\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 963\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m    964\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    965\u001b[0m     def evaluate(self, x=None, y=None,\n",
            "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/Keras-2.1.5-py3.6.egg/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1703\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1704\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1705\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1707\u001b[0m     def evaluate(self, x=None, y=None,\n",
            "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/Keras-2.1.5-py3.6.egg/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1233\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1235\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1236\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1237\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/Keras-2.1.5-py3.6.egg/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2477\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2478\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2479\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2480\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2481\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    906\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 908\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    909\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    910\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1141\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1142\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1143\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1144\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1145\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1324\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1325\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1328\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1330\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1331\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1332\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1313\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1314\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1315\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1316\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1317\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1421\u001b[0m         return tf_session.TF_Run(\n\u001b[1;32m   1422\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1423\u001b[0;31m             status, run_metadata)\n\u001b[0m\u001b[1;32m   1424\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1425\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "_uuid": "fd2138fd181f6d8302bc5d5697453bbdc8ff3f98"
      },
      "cell_type": "markdown",
      "source": "## Test "
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "64ea1632ab83398264b37480e87db3e4f5b60a34"
      },
      "cell_type": "code",
      "source": "score, acc = model.evaluate(X_test, test_labels, batch_size=batch_size)\nprint('Test score:', score)\nprint('Test accuracy:', acc)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": false,
        "collapsed": true,
        "_uuid": "acef6b1a5a1a67b835411a82d7e5e16c6290ec0a"
      },
      "cell_type": "markdown",
      "source": "# Modelo de QRNN"
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "c0a46ccfc7a93b28c987500513d13ca98e25c216"
      },
      "cell_type": "code",
      "source": "from keras.models import Model, Sequential\nfrom keras.layers import Dense, Embedding, Input, Conv1D, GlobalMaxPool1D, Dropout, concatenate, Layer, InputSpec, CuDNNLSTM\nfrom keras.preprocessing import text, sequence\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint\nfrom keras import backend as K\nfrom keras import activations, initializers, regularizers, constraints\nfrom keras.utils.conv_utils import conv_output_length\nfrom keras.regularizers import l2\nfrom keras.constraints import maxnorm",
      "execution_count": 64,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "ba984b7e4742b9e3378cb219ca9815aec1ed4630"
      },
      "cell_type": "code",
      "source": "def cudnnlstm_model(conv_layers = 2, max_dilation_rate = 3):\n    embed_size = 128\n    inp = Input(shape=(maxlen, ))\n    x = Embedding(max_features, embed_size)(inp)\n    x = Dropout(0.25)(x)\n    x = Conv1D(2*embed_size, kernel_size = 3)(x)\n    prefilt = Conv1D(2*embed_size, kernel_size = 3)(x)\n    x = prefilt\n    for strides in [1, 1, 2]:\n        x = Conv1D(128*2**(strides), strides = strides, kernel_regularizer=l2(4e-6), bias_regularizer=l2(4e-6), kernel_size=3, kernel_constraint=maxnorm(10), bias_constraint=maxnorm(10))(x)\n    x_f = CuDNNLSTM(512, kernel_regularizer=l2(4e-6), bias_regularizer=l2(4e-6), kernel_constraint=maxnorm(10), bias_constraint=maxnorm(10))(x)  \n    x_b = CuDNNLSTM(512, kernel_regularizer=l2(4e-6), bias_regularizer=l2(4e-6), kernel_constraint=maxnorm(10), bias_constraint=maxnorm(10))(x)\n    x = concatenate([x_f, x_b])\n    x = Dropout(0.5)(x)\n    x = Dense(64, activation=\"relu\")(x)\n    x = Dropout(0.1)(x)\n    x = Dense(1, activation=\"sigmoid\")(x)\n    model = Model(inputs=inp, outputs=x)\n    model.compile(loss='binary_crossentropy',\n                  optimizer='adam',\n                  metrics=['binary_accuracy'])\n\n    return model\n\ncudnnlstm_model = cudnnlstm_model()\ncudnnlstm_model.summary()\n\nbatch_size = 2048\nepochs = 4\n\nweight_path=\"early_weights.hdf5\"\ncheckpoint = ModelCheckpoint(weight_path, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\nearly_stopping = EarlyStopping(monitor=\"val_loss\", mode=\"min\", patience=5)\ncallbacks = [checkpoint, early_stopping]",
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse the retry module or similar alternatives.\n",
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": "/opt/conda/lib/python3.6/site-packages/numexpr/cpuinfo.py:42: UserWarning: [Errno 12] Cannot allocate memory\n  warnings.warn(str(e), UserWarning, stacklevel=stacklevel)\n",
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": "__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\ninput_2 (InputLayer)            (None, 100)          0                                            \n__________________________________________________________________________________________________\nembedding_20 (Embedding)        (None, 100, 128)     2560000     input_2[0][0]                    \n__________________________________________________________________________________________________\ndropout_39 (Dropout)            (None, 100, 128)     0           embedding_20[0][0]               \n__________________________________________________________________________________________________\nconv1d_3 (Conv1D)               (None, 98, 256)      98560       dropout_39[0][0]                 \n__________________________________________________________________________________________________\nconv1d_4 (Conv1D)               (None, 96, 256)      196864      conv1d_3[0][0]                   \n__________________________________________________________________________________________________\nconv1d_5 (Conv1D)               (None, 94, 256)      196864      conv1d_4[0][0]                   \n__________________________________________________________________________________________________\nconv1d_6 (Conv1D)               (None, 92, 256)      196864      conv1d_5[0][0]                   \n__________________________________________________________________________________________________\nconv1d_7 (Conv1D)               (None, 45, 512)      393728      conv1d_6[0][0]                   \n__________________________________________________________________________________________________\ncu_dnnlstm_1 (CuDNNLSTM)        (None, 512)          2101248     conv1d_7[0][0]                   \n__________________________________________________________________________________________________\ncu_dnnlstm_2 (CuDNNLSTM)        (None, 512)          2101248     conv1d_7[0][0]                   \n__________________________________________________________________________________________________\nconcatenate_1 (Concatenate)     (None, 1024)         0           cu_dnnlstm_1[0][0]               \n                                                                 cu_dnnlstm_2[0][0]               \n__________________________________________________________________________________________________\ndropout_40 (Dropout)            (None, 1024)         0           concatenate_1[0][0]              \n__________________________________________________________________________________________________\ndense_30 (Dense)                (None, 64)           65600       dropout_40[0][0]                 \n__________________________________________________________________________________________________\ndropout_41 (Dropout)            (None, 64)           0           dense_30[0][0]                   \n__________________________________________________________________________________________________\ndense_31 (Dense)                (None, 1)            65          dropout_41[0][0]                 \n==================================================================================================\nTotal params: 7,911,041\nTrainable params: 7,911,041\nNon-trainable params: 0\n__________________________________________________________________________________________________\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "scrolled": true,
        "_uuid": "37ed5bb48df021a0227e3c6260313d403e977b0a"
      },
      "cell_type": "code",
      "source": "cudnnlstm_model.fit(X_train[:100000]\n                    ,train_labels[:100000]\n                    ,batch_size=batch_size\n                    ,epochs=epochs\n                    ,shuffle = True\n                    ,validation_split=0.20\n                    ,callbacks=callbacks)",
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Train on 80000 samples, validate on 20000 samples\nEpoch 1/4\n80000/80000 [==============================] - 82s 1ms/step - loss: 0.4193 - binary_accuracy: 0.8194 - val_loss: 0.3489 - val_binary_accuracy: 0.8630\n\nEpoch 00001: val_loss improved from inf to 0.34887, saving model to early_weights.hdf5\nEpoch 2/4\n80000/80000 [==============================] - 81s 1ms/step - loss: 0.2844 - binary_accuracy: 0.8912 - val_loss: 0.3096 - val_binary_accuracy: 0.8774\n\nEpoch 00002: val_loss improved from 0.34887 to 0.30955, saving model to early_weights.hdf5\nEpoch 3/4\n80000/80000 [==============================] - 81s 1ms/step - loss: 0.2288 - binary_accuracy: 0.9163 - val_loss: 0.2786 - val_binary_accuracy: 0.8899\n\nEpoch 00003: val_loss improved from 0.30955 to 0.27859, saving model to early_weights.hdf5\nEpoch 4/4\n80000/80000 [==============================] - 81s 1ms/step - loss: 0.1987 - binary_accuracy: 0.9291 - val_loss: 0.3181 - val_binary_accuracy: 0.8794\n\nEpoch 00004: val_loss did not improve\n",
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "execution_count": 68,
          "data": {
            "text/plain": "<keras.callbacks.History at 0x7f0b3c74b470>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "a87cb19d5a9d807a1e34fe5a71f7ec905dcd8f8e"
      },
      "cell_type": "code",
      "source": "cudnnlstm_model.load_weights(weight_path)\nscore, acc = cudnnlstm_model.evaluate(X_test, test_labels, batch_size=batch_size)\nprint('Test score:', score)\nprint('Test accuracy:', acc)",
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": "400000/400000 [==============================] - 126s 315us/step\nTest score: 0.2790753042125702\nTest accuracy: 0.8894675\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "eb8e0111fcd782ec13d69743ef021ad75fdcc791"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.4",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}